{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# misc\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import ast\n",
    "import warnings\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "import scikitplot as skplt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive \n",
    "drive.mount('/content/drive')\n",
    "os.chdir('/content/drive/My Drive/Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"df_final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Headline', # not a feature for training\n",
    "    'Bias',\n",
    " 'glove_vec300_norm',\n",
    " 'tf_idf',\n",
    " 'negative',\n",
    " 'positive',\n",
    " 'bias_lex_h',\n",
    "'bias_lex_r',\n",
    " 'assertives',\n",
    " 'factives',\n",
    " 'report_verbs',\n",
    " 'implicatives',\n",
    " 'hedges',\n",
    " 'affect (Affect)',\n",
    " 'posemo (Positive Emotions)',\n",
    " 'negemo (Negative Emotions)',\n",
    " 'anx (Anx)',\n",
    " 'anger (Anger)',\n",
    " 'sad (Sad)',\n",
    " 'social (Social)',\n",
    " 'family (Family)',\n",
    " 'friend (Friends)',\n",
    " 'female (Female)',\n",
    " 'male (Male)',\n",
    " 'cogproc (Cognitive Processes)',\n",
    " 'insight (Insight)',\n",
    " 'cause (Causal)',\n",
    " 'discrep (Discrepancies)',\n",
    " 'tentat (Tentative)',\n",
    " 'certain (Certainty)',\n",
    " 'differ (Differentiation)',\n",
    " 'percept (Perceptual Processes)',\n",
    " 'see (See)',\n",
    " 'hear (Hear)',\n",
    " 'feel (Feel)',\n",
    " 'bio (Biological Processes)',\n",
    " 'body (Body)',\n",
    " 'health (Health)',\n",
    " 'sexual (Sexual)',\n",
    " 'ingest (Ingest)',\n",
    " 'drives (Drives)',\n",
    " 'affiliation (Affiliation)',\n",
    " 'achieve (Achievement)',\n",
    " 'power (Power)',\n",
    " 'reward (Reward)',\n",
    " 'risk (Risk)',\n",
    " 'focuspast (Past Focus)',\n",
    " 'focuspresent (Present Focus)',\n",
    " 'focusfuture (Future Focus)',\n",
    " 'relativ (Relativity)',\n",
    " 'motion (Motion)',\n",
    " 'space (Space)',\n",
    " 'time (Time)',\n",
    " 'work (Work)',\n",
    " 'leisure (Leisure)',\n",
    " 'home (Home)',\n",
    " 'money (Money)',\n",
    " 'relig (Religion)',\n",
    " 'death (Death)',\n",
    " 'informal (Informal Language)',\n",
    " 'swear (Swear)',\n",
    " 'netspeak (Netspeak)',\n",
    " 'assent (Assent)',\n",
    " 'nonflu (Nonfluencies)',\n",
    " 'filler (Filler Words)',\n",
    " 'pos_ADJ',\n",
    " 'pos_ADP',\n",
    " 'pos_ADV',\n",
    " 'pos_AUX',\n",
    " 'pos_DET',\n",
    " 'pos_INTJ',\n",
    " 'pos_NOUN',\n",
    " 'pos_PRON',\n",
    " 'pos_PROPN',\n",
    " 'pos_SCONJ',\n",
    " 'pos_VERB',\n",
    " 'pos_X',\n",
    " 'dep_ROOT',\n",
    " 'dep_acl',\n",
    " 'dep_acomp',\n",
    " 'dep_advcl',\n",
    " 'dep_advmod',\n",
    " 'dep_agent',\n",
    " 'dep_amod',\n",
    " 'dep_appos',\n",
    " 'dep_attr',\n",
    " 'dep_aux',\n",
    " 'dep_auxpass',\n",
    " 'dep_cc',\n",
    " 'dep_ccomp',\n",
    " 'dep_compound',\n",
    " 'dep_conj',\n",
    " 'dep_csubj',\n",
    " 'dep_dative',\n",
    " 'dep_dep',\n",
    " 'dep_det',\n",
    " 'dep_dobj',\n",
    " 'dep_expl',\n",
    " 'dep_intj',\n",
    " 'dep_mark',\n",
    " 'dep_neg',\n",
    " 'dep_nmod',\n",
    " 'dep_npadvmod',\n",
    " 'dep_nsubj',\n",
    " 'dep_nsubjpass',\n",
    " 'dep_nummod',\n",
    " 'dep_oprd',\n",
    " 'dep_parataxis',\n",
    " 'dep_pcomp',\n",
    " 'dep_pobj',\n",
    " 'dep_poss',\n",
    " 'dep_preconj',\n",
    " 'dep_predet',\n",
    " 'dep_prep',\n",
    " 'dep_prt',\n",
    " 'dep_punct',\n",
    " 'dep_quantmod',\n",
    " 'dep_relcl',\n",
    " 'dep_xcomp',\n",
    " 'ne_CARDINAL',\n",
    " 'ne_DATE',\n",
    " 'ne_EVENT',\n",
    " 'ne_FAC',\n",
    " 'ne_GPE',\n",
    " 'ne_LANGUAGE',\n",
    " 'ne_LAW',\n",
    " 'ne_LOC',\n",
    " 'ne_MONEY',\n",
    " 'ne_NORP',\n",
    " 'ne_ORDINAL',\n",
    " 'ne_ORG',\n",
    " 'ne_PERCENT',\n",
    " 'ne_PERSON',\n",
    " 'ne_PRODUCT',\n",
    " 'ne_QUANTITY',\n",
    " 'ne_TIME',\n",
    " 'ne_WORK_OF_ART',\n",
    " 'negative_context',\n",
    " 'positive_context',\n",
    " 'bias_lex_h_context',\n",
    "'bias_lex_r_context',\n",
    " 'assertives_context',\n",
    " 'factives_context',\n",
    " 'report_verbs_context',\n",
    " 'implicatives_context',\n",
    " 'hedges_context',\n",
    "'affect (Affect)_context',\n",
    " 'posemo (Positive Emotions)_context',\n",
    " 'negemo (Negative Emotions)_context',\n",
    " 'anx (Anx)_context',\n",
    " 'anger (Anger)_context',\n",
    " 'sad (Sad)_context',\n",
    " 'social (Social)_context',\n",
    " 'family (Family)_context',\n",
    " 'friend (Friends)_context',\n",
    " 'female (Female)_context',\n",
    " 'male (Male)_context',\n",
    " 'cogproc (Cognitive Processes)_context',\n",
    " 'insight (Insight)_context',\n",
    " 'cause (Causal)_context',\n",
    " 'discrep (Discrepancies)_context',\n",
    " 'tentat (Tentative)_context',\n",
    " 'certain (Certainty)_context',\n",
    " 'differ (Differentiation)_context',\n",
    " 'percept (Perceptual Processes)_context',\n",
    " 'see (See)_context',\n",
    " 'hear (Hear)_context',\n",
    " 'feel (Feel)_context',\n",
    " 'bio (Biological Processes)_context',\n",
    " 'body (Body)_context',\n",
    " 'health (Health)_context',\n",
    " 'sexual (Sexual)_context',\n",
    " 'ingest (Ingest)_context',\n",
    " 'drives (Drives)_context',\n",
    " 'affiliation (Affiliation)_context',\n",
    " 'achieve (Achievement)_context',\n",
    " 'power (Power)_context',\n",
    " 'reward (Reward)_context',\n",
    " 'risk (Risk)_context',\n",
    " 'focuspast (Past Focus)_context',\n",
    " 'focuspresent (Present Focus)_context',\n",
    " 'focusfuture (Future Focus)_context',\n",
    " 'relativ (Relativity)_context',\n",
    " 'motion (Motion)_context',\n",
    " 'space (Space)_context',\n",
    " 'time (Time)_context',\n",
    " 'work (Work)_context',\n",
    " 'leisure (Leisure)_context',\n",
    " 'home (Home)_context',\n",
    " 'money (Money)_context',\n",
    " 'relig (Religion)_context',\n",
    " 'death (Death)_context',\n",
    " 'informal (Informal Language)_context',\n",
    " 'swear (Swear)_context',\n",
    " 'netspeak (Netspeak)_context',\n",
    " 'assent (Assent)_context',\n",
    " 'nonflu (Nonfluencies)_context',\n",
    " 'filler (Filler Words)_context',\n",
    " 'pos_ADJ_context',\n",
    " 'pos_ADP_context',\n",
    " 'pos_ADV_context',\n",
    " 'pos_AUX_context',\n",
    " 'pos_DET_context',\n",
    " 'pos_INTJ_context',\n",
    " 'pos_NOUN_context',\n",
    " 'pos_PRON_context',\n",
    " 'pos_PROPN_context',\n",
    " 'pos_SCONJ_context',\n",
    " 'pos_VERB_context',\n",
    " 'pos_X_context',\n",
    " 'dep_ROOT_context',\n",
    " 'dep_acl_context',\n",
    " 'dep_acomp_context',\n",
    " 'dep_advcl_context',\n",
    " 'dep_advmod_context',\n",
    " 'dep_agent_context',\n",
    " 'dep_amod_context',\n",
    " 'dep_appos_context',\n",
    " 'dep_attr_context',\n",
    " 'dep_aux_context',\n",
    " 'dep_auxpass_context',\n",
    " 'dep_cc_context',\n",
    " 'dep_ccomp_context',\n",
    " 'dep_compound_context',\n",
    " 'dep_conj_context',\n",
    " 'dep_csubj_context',\n",
    " 'dep_dative_context',\n",
    " 'dep_dep_context',\n",
    " 'dep_det_context',\n",
    " 'dep_dobj_context',\n",
    " 'dep_expl_context',\n",
    " 'dep_intj_context',\n",
    " 'dep_mark_context',\n",
    " 'dep_neg_context',\n",
    " 'dep_nmod_context',\n",
    " 'dep_npadvmod_context',\n",
    " 'dep_nsubj_context',\n",
    " 'dep_nsubjpass_context',\n",
    " 'dep_nummod_context',\n",
    " 'dep_oprd_context',\n",
    " 'dep_parataxis_context',\n",
    " 'dep_pcomp_context',\n",
    " 'dep_pobj_context',\n",
    " 'dep_poss_context',\n",
    " 'dep_preconj_context',\n",
    " 'dep_predet_context',\n",
    " 'dep_prep_context',\n",
    " 'dep_prt_context',\n",
    " 'dep_punct_context',\n",
    " 'dep_quantmod_context',\n",
    " 'dep_relcl_context',\n",
    " 'dep_xcomp_context',\n",
    " 'ne_CARDINAL_context',\n",
    " 'ne_DATE_context',\n",
    " 'ne_EVENT_context',\n",
    " 'ne_FAC_context',\n",
    " 'ne_GPE_context',\n",
    " 'ne_LAW_context',\n",
    " 'ne_LOC_context',\n",
    " 'ne_MONEY_context',\n",
    " 'ne_NORP_context',\n",
    " 'ne_ORDINAL_context',\n",
    " 'ne_ORG_context',\n",
    " 'ne_PERCENT_context',\n",
    " 'ne_PERSON_context',\n",
    " 'ne_PRODUCT_context',\n",
    " 'ne_QUANTITY_context',\n",
    " 'ne_TIME_context',\n",
    " 'ne_WORK_OF_ART_context',\n",
    " 'ne_LANGUAGE_context']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Label\"] == df.Bias.apply(lambda x: 1 if x == \"AllSides Media Bias Rating: Left\" or x == \"AllSides Media Bias Rating: Right\" else (0 if x == \"AllSides Media Bias Rating: Center\" else -99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Label\"] > -50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['Label'], 1)\n",
    "y = df[['Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_scaled = copy.deepcopy(x)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_scaled['glove_vec300_norm'] = scaler.fit_transform(x_scaled[['glove_vec300_norm']])\n",
    "x_scaled['tf_idf'] = scaler.fit_transform(x_scaled[['tf_idf']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(x, y, \n",
    "                                                                            test_size = 0.20, random_state = 42)\n",
    "train_features_sc, test_features_sc, train_labels, test_labels = train_test_split(x_scaled, y, \n",
    "                                                                            test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['accuracy', 'f1', 'roc_auc', 'precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Biased words:',round(len(y[y['Label']==1])/len(y)*100,0),'%')\n",
    "print('Biased words:',round(len(y[y['Label']==0])/len(y)*100,0),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_w = LogisticRegressionCV(random_state=42, class_weight = {0:10, 1:90})\n",
    "scores_logreg_w = cross_validate(logreg_w, x_scaled, y, cv=10, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores_logreg_w['test_f1'].mean(), scores_logreg_w['test_f1'].std() * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (scores_logreg_w['test_precision'].mean(), scores_logreg_w['test_precision'].std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (scores_logreg_w['test_recall'].mean(), scores_logreg_w['test_recall'].std() * 2))\n",
    "print(\"AUC: %0.2f (+/- %0.2f)\" % (scores_logreg_w['test_roc_auc'].mean(), scores_logreg_w['test_roc_auc'].std() * 2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_logreg_w['test_accuracy'].mean(), scores_logreg_w['test_accuracy'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logreg_w_cm = logreg_w.fit(train_features_sc, train_labels).predict(test_features_sc)\n",
    "pred_binary_logreg_w_cm = pred_logreg_w_cm.round()\n",
    "print('Confusion matrix:\\n', metrics.confusion_matrix(test_labels, pred_binary_logreg_w_cm).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "scores_lda = cross_validate(lda, x_scaled, y, cv=10, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores_lda['test_f1'].mean(), scores_lda['test_f1'].std() * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (scores_lda['test_precision'].mean(), scores_lda['test_precision'].std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (scores_lda['test_recall'].mean(), scores_lda['test_recall'].std() * 2))\n",
    "print(\"AUC: %0.2f (+/- %0.2f)\" % (scores_lda['test_roc_auc'].mean(), scores_lda['test_roc_auc'].std() * 2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_lda['test_accuracy'].mean(), scores_lda['test_accuracy'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lda_cm = lda.fit(train_features_sc, train_labels).predict(test_features_sc)\n",
    "pred_binary_lda_cm = pred_lda_cm.round()\n",
    "print('Confusion matrix:\\n', metrics.confusion_matrix(test_labels, pred_binary_lda_cm).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "scores_qda = cross_validate(qda, x_scaled, y, cv=10, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores_qda['test_f1'].mean(), scores_qda['test_f1'].std() * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (scores_qda['test_precision'].mean(), scores_qda['test_precision'].std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (scores_qda['test_recall'].mean(), scores_qda['test_recall'].std() * 2))\n",
    "print(\"AUC: %0.2f (+/- %0.2f)\" % (scores_qda['test_roc_auc'].mean(), scores_qda['test_roc_auc'].std() * 2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_qda['test_accuracy'].mean(), scores_qda['test_accuracy'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_qda_cm = qda.fit(train_features_sc, train_labels).predict(test_features_sc)\n",
    "pred_binary_qda_cm = pred_qda_cm.round()\n",
    "print('Confusion matrix:\\n', metrics.confusion_matrix(test_labels, pred_binary_qda_cm).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "scores_nb = cross_validate(nb, x_scaled, y, cv=10, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores_nb['test_f1'].mean(), scores_nb['test_f1'].std() * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (scores_nb['test_precision'].mean(), scores_nb['test_precision'].std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (scores_nb['test_recall'].mean(), scores_nb['test_recall'].std() * 2))\n",
    "print(\"AUC: %0.2f (+/- %0.2f)\" % (scores_nb['test_roc_auc'].mean(), scores_nb['test_roc_auc'].std() * 2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_nb['test_accuracy'].mean(), scores_nb['test_accuracy'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_nb_cm = nb.fit(train_features_sc, train_labels).predict(test_features_sc)\n",
    "pred_binary_nb_cm = pred_nb_cm.round()\n",
    "print('Confusion matrix:\\n', metrics.confusion_matrix(test_labels, pred_binary_nb_cm).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_imb = ComplementNB()\n",
    "scores_nb_imb = cross_validate(nb_imb, x_scaled, y, cv=10, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores_nb_imb['test_f1'].mean(), scores_nb_imb['test_f1'].std() * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (scores_nb_imb['test_precision'].mean(), scores_nb_imb['test_precision'].std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (scores_nb_imb['test_recall'].mean(), scores_nb_imb['test_recall'].std() * 2))\n",
    "print(\"AUC: %0.2f (+/- %0.2f)\" % (scores_nb_imb['test_roc_auc'].mean(), scores_nb_imb['test_roc_auc'].std() * 2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_nb_imb['test_accuracy'].mean(), scores_nb_imb['test_accuracy'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_nb_imb_cm = nb_imb.fit(train_features_sc, train_labels).predict(test_features_sc)\n",
    "pred_binary_nb_imb_cm = pred_nb_imb_cm.round()\n",
    "print('Confusion matrix:\\n', metrics.confusion_matrix(test_labels, pred_binary_nb_imb_cm).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "scores_knn = cross_validate(knn, x_scaled, y, cv=10, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores_knn['test_f1'].mean(), scores_knn['test_f1'].std() * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (scores_knn['test_precision'].mean(), scores_knn['test_precision'].std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (scores_knn['test_recall'].mean(), scores_knn['test_recall'].std() * 2))\n",
    "print(\"AUC: %0.2f (+/- %0.2f)\" % (scores_knn['test_roc_auc'].mean(), scores_knn['test_roc_auc'].std() * 2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_knn['test_accuracy'].mean(), scores_knn['test_accuracy'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_knn_cm = knn.fit(train_features_sc, train_labels).predict(test_features_sc)\n",
    "pred_binary_knn_cm = pred_knn_cm.round()\n",
    "print('Confusion matrix:\\n', metrics.confusion_matrix(test_labels, pred_binary_knn_cm).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "scores_dt = cross_validate(dt, x, y, cv=10, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores_dt['test_f1'].mean(), scores_dt['test_f1'].std() * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (scores_dt['test_precision'].mean(), scores_dt['test_precision'].std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (scores_dt['test_recall'].mean(), scores_dt['test_recall'].std() * 2))\n",
    "print(\"AUC: %0.2f (+/- %0.2f)\" % (scores_dt['test_roc_auc'].mean(), scores_dt['test_roc_auc'].std() * 2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_dt['test_accuracy'].mean(), scores_dt['test_accuracy'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dt_cm = dt.fit(train_features, train_labels).predict(test_features)\n",
    "pred_binary_dt_cm = pred_dt_cm.round()\n",
    "print('Confusion matrix:\\n', metrics.confusion_matrix(test_labels, pred_binary_dt_cm).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_w = DecisionTreeClassifier(random_state=42, class_weight = {0:10, 1:90})\n",
    "scores_dt_w = cross_validate(dt_w, x, y, cv=10, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores_dt_w['test_f1'].mean(), scores_dt_w['test_f1'].std() * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (scores_dt_w['test_precision'].mean(), scores_dt_w['test_precision'].std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (scores_dt_w['test_recall'].mean(), scores_dt_w['test_recall'].std() * 2))\n",
    "print(\"AUC: %0.2f (+/- %0.2f)\" % (scores_dt_w['test_roc_auc'].mean(), scores_dt_w['test_roc_auc'].std() * 2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_dt_w['test_accuracy'].mean(), scores_dt_w['test_accuracy'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dt_w_cm = dt_w.fit(train_features, train_labels).predict(test_features)\n",
    "pred_binary_dt_w_cm = pred_dt_w_cm.round()\n",
    "print('Confusion matrix:\\n', metrics.confusion_matrix(test_labels, pred_binary_dt_w_cm).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "scores_rf = cross_validate(rf, x, y, cv=10, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores_rf['test_f1'].mean(), scores_rf['test_f1'].std() * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (scores_rf['test_precision'].mean(), scores_rf['test_precision'].std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (scores_rf['test_recall'].mean(), scores_rf['test_recall'].std() * 2))\n",
    "print(\"AUC: %0.2f (+/- %0.2f)\" % (scores_rf['test_roc_auc'].mean(), scores_rf['test_roc_auc'].std() * 2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_rf['test_accuracy'].mean(), scores_rf['test_accuracy'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf_cm = rf.fit(train_features, train_labels).predict(test_features)\n",
    "pred_binary_rf_cm = pred_rf_cm.round()\n",
    "print('Confusion matrix:\\n', metrics.confusion_matrix(test_labels, pred_binary_rf_cm).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_w = RandomForestClassifier(random_state=42, class_weight = {0:10, 1:90}, n_estimators=100)\n",
    "scores_rf_w = cross_validate(rf_w, x, y, cv=10, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores_rf_w['test_f1'].mean(), scores_rf_w['test_f1'].std() * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (scores_rf_w['test_precision'].mean(), scores_rf_w['test_precision'].std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (scores_rf_w['test_recall'].mean(), scores_rf_w['test_recall'].std() * 2))\n",
    "print(\"AUC: %0.2f (+/- %0.2f)\" % (scores_rf_w['test_roc_auc'].mean(), scores_rf_w['test_roc_auc'].std() * 2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_rf_w['test_accuracy'].mean(), scores_rf_w['test_accuracy'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf_w_cm = rf_w.fit(train_features, train_labels).predict(test_features)\n",
    "pred_binary_rf_w_cm = pred_rf_w_cm.round()\n",
    "print('Confusion matrix:\\n', metrics.confusion_matrix(test_labels, pred_binary_rf_w_cm).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear', random_state=42)\n",
    "scores_svm = cross_validate(svm, x_scaled, y, cv=10, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores_svm['test_f1'].mean(), scores_svm['test_f1'].std() * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (scores_svm['test_precision'].mean(), scores_svm['test_precision'].std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (scores_svm['test_recall'].mean(), scores_svm['test_recall'].std() * 2))\n",
    "print(\"AUC: %0.2f (+/- %0.2f)\" % (scores_svm['test_roc_auc'].mean(), scores_svm['test_roc_auc'].std() * 2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_svm['test_accuracy'].mean(), scores_svm['test_accuracy'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm_cm = svm.fit(train_features_sc, train_labels).predict(test_features_sc)\n",
    "pred_binary_svm_cm = pred_svm_cm.round()\n",
    "print('Confusion matrix:\\n', metrics.confusion_matrix(test_labels, pred_binary_svm_cm).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "svm_w = SVC(kernel='linear', random_state=42, class_weight = {0:10, 1:90})\n",
    "scores_svm_w = cross_validate(svm_w, x_scaled, y, cv=5, scoring=scoring)\n",
    "end_time = time.time()\n",
    "print('Time to train weighted linear SVM on all features, 10-fold CV:', round((end_time-start_time),2), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores_svm_w['test_f1'].mean(), scores_svm_w['test_f1'].std() * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (scores_svm_w['test_precision'].mean(), scores_svm_w['test_precision'].std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (scores_svm_w['test_recall'].mean(), scores_svm_w['test_recall'].std() * 2))\n",
    "print(\"AUC: %0.2f (+/- %0.2f)\" % (scores_svm_w['test_roc_auc'].mean(), scores_svm_w['test_roc_auc'].std() * 2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_svm_w['test_accuracy'].mean(), scores_svm_w['test_accuracy'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "pred_svm_w_cm = svm_w.fit(train_features_sc, train_labels).predict(test_features_sc)\n",
    "pred_binary_svm_w_cm = pred_svm_w_cm.round()\n",
    "print('Confusion matrix:\\n', metrics.confusion_matrix(test_labels, pred_binary_svm_w_cm).transpose())\n",
    "end_time = time.time()\n",
    "print('Time to train weighted linear SVM on all features, 10-fold CV:', round((end_time-start_time),2), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "svm_w = SVC(random_state=42, class_weight = {0:10, 1:90})\n",
    "scores_svm_w = cross_validate(svm_w, x_scaled, y, cv=5, scoring=scoring)\n",
    "end_time = time.time()\n",
    "print('Time to train weighted linear SVM on all features, 10-fold CV:', round((end_time-start_time),2), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores_svm_w['test_f1'].mean(), scores_svm_w['test_f1'].std() * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (scores_svm_w['test_precision'].mean(), scores_svm_w['test_precision'].std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (scores_svm_w['test_recall'].mean(), scores_svm_w['test_recall'].std() * 2))\n",
    "print(\"AUC: %0.2f (+/- %0.2f)\" % (scores_svm_w['test_roc_auc'].mean(), scores_svm_w['test_roc_auc'].std() * 2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_svm_w['test_accuracy'].mean(), scores_svm_w['test_accuracy'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "pred_svm_w_cm = svm_w.fit(train_features_sc, train_labels).predict(test_features_sc)\n",
    "pred_binary_svm_w_cm = pred_svm_w_cm.round()\n",
    "print('Confusion matrix:\\n', metrics.confusion_matrix(test_labels, pred_binary_svm_w_cm).transpose())\n",
    "end_time = time.time()\n",
    "print('Time to train weighted linear SVM on all features, 10-fold CV:', round((end_time-start_time),2), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "scores_xgb = cross_validate(xgb, x, y, cv=10, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores_xgb['test_f1'].mean(), scores_xgb['test_f1'].std() * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (scores_xgb['test_precision'].mean(), scores_xgb['test_precision'].std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (scores_xgb['test_recall'].mean(), scores_xgb['test_recall'].std() * 2))\n",
    "print(\"AUC: %0.2f (+/- %0.2f)\" % (scores_xgb['test_roc_auc'].mean(), scores_xgb['test_roc_auc'].std() * 2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_xgb['test_accuracy'].mean(), scores_xgb['test_accuracy'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgb_cm = xgb.fit(train_features, train_labels).predict(test_features)\n",
    "pred_binary_xgb_cm = pred_xgb_cm.round()\n",
    "print('Confusion matrix:\\n', metrics.confusion_matrix(test_labels, pred_binary_xgb_cm).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scale_pos_weight = len(y[y['label4']==0])/len(y[y['Label']==1])\n",
    "scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_w = xgboost.XGBClassifier(objective=\"binary:logistic\", scale_pos_weight=scale_pos_weight, random_state=42)\n",
    "scores_xgb_w = cross_validate(xgb_w, x, y, cv=10, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores_xgb_w['test_f1'].mean(), scores_xgb_w['test_f1'].std() * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (scores_xgb_w['test_precision'].mean(), scores_xgb_w['test_precision'].std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (scores_xgb_w['test_recall'].mean(), scores_xgb_w['test_recall'].std() * 2))\n",
    "print(\"AUC: %0.2f (+/- %0.2f)\" % (scores_xgb_w['test_roc_auc'].mean(), scores_xgb_w['test_roc_auc'].std() * 2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_xgb_w['test_accuracy'].mean(), scores_xgb_w['test_accuracy'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgb_w_cm = xgb_w.fit(train_features, train_labels).predict(test_features)\n",
    "pred_binary_xgb_w_cm = pred_xgb_w_cm.round()\n",
    "print('Confusion matrix:\\n', metrics.confusion_matrix(test_labels, pred_binary_xgb_w_cm).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state=42)\n",
    "scores_mlp = cross_validate(mlp, x_scaled, y4, cv=10, scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1: %0.2f (+/- %0.2f)\" % (scores_mlp['test_f1'].mean(), scores_mlp['test_f1'].std() * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (scores_mlp['test_precision'].mean(), scores_mlp['test_precision'].std() * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (scores_mlp['test_recall'].mean(), scores_mlp['test_recall'].std() * 2))\n",
    "print(\"AUC: %0.2f (+/- %0.2f)\" % (scores_mlp['test_roc_auc'].mean(), scores_mlp['test_roc_auc'].std() * 2))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_mlp['test_accuracy'].mean(), scores_mlp['test_accuracy'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mlp_cm = mlp.fit(train_features_sc, train_labels).predict(test_features_sc)\n",
    "pred_binary_mlp_cm = pred_mlp_cm.round()\n",
    "print('Confusion matrix:\\n', metrics.confusion_matrix(test_labels, pred_binary_mlp_cm).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(n_input):\n",
    "    # define model\n",
    "    mlp_w = Sequential()\n",
    "    # define first hidden layer and visible layer\n",
    "    mlp_w.add(layers.Dense(100, input_dim=n_input, activation='relu'))\n",
    "    # define output layer\n",
    "    mlp_w.add(layers.Dense(1, activation='sigmoid'))\n",
    "    # define loss and optimizer\n",
    "    mlp_w.compile(loss='binary_crossentropy', optimizer='adam', metrics=['AUC','Precision','Recall'])\n",
    "    return mlp_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-735d314ab998>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# K-fold Cross Validation model evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnum_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfold_no\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "# K-fold Cross Validation model evaluation\n",
    "start_time = time.time()\n",
    "\n",
    "num_folds = 10\n",
    "fold_no = 1\n",
    "F1_per_fold = []\n",
    "precision_per_fold = []\n",
    "recall_per_fold = []\n",
    "AUC_per_fold = []\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "x_scaled_np = x_scaled.to_numpy()\n",
    "y_np = y.to_numpy()\n",
    "\n",
    "for train_index, test_index in kf.split(x_scaled_np):\n",
    "    X_train, X_test = x_scaled_np[train_index], x_scaled_np[test_index]\n",
    "    y_train, y_test = y_np[train_index], y_np[test_index]\n",
    "\n",
    "    # Generate a print\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    mlp_w = define_model(len(feature_list))\n",
    "\n",
    "    # Fit data to model\n",
    "    mlp_w.fit(X_train, y_train, epochs=200, class_weight={0:10, 1:90})\n",
    "    mlp_w_pred = mlp_w.predict(X_test)\n",
    "    mlp_w_pred_bin = mlp_w_pred.round()\n",
    "    \n",
    "    F1_per_fold.append(metrics.f1_score(y_test, mlp_w_pred_bin, pos_label=1))\n",
    "    precision_per_fold.append(metrics.precision_score(y_test, mlp_w_pred_bin, pos_label=1))\n",
    "    recall_per_fold.append(metrics.recall_score(y_test, mlp_w_pred_bin, pos_label=1))\n",
    "    AUC_per_fold.append(metrics.roc_auc_score(y_test, mlp_w_pred_bin))\n",
    "    print('CF:', metrics.confusion_matrix(y_test, mlp_w_pred_bin).transpose())\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "end_time = time.time()\n",
    "print('Time to train weighted MLP on all features, 10-fold CV:', round((end_time-start_time),2), 'seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1: %0.2f (+/- %0.2f)\" % (statistics.mean(F1_per_fold), statistics.pstdev(F1_per_fold) * 2))\n",
    "print(\"Precision: %0.2f (+/- %0.2f)\" % (statistics.mean(precision_per_fold), statistics.pstdev(precision_per_fold) * 2))\n",
    "print(\"Recall: %0.2f (+/- %0.2f)\" % (statistics.mean(recall_per_fold), statistics.pstdev(recall_per_fold) * 2))\n",
    "print(\"AUC: %0.2f (+/- %0.2f)\" % (statistics.mean(AUC_per_fold), statistics.pstdev(AUC_per_fold) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
