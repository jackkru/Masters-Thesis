{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-plot in c:\\users\\jack\\anaconda3\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from scikit-plot) (0.23.1)\n",
      "Requirement already satisfied: joblib>=0.10 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from scikit-plot) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.9 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from scikit-plot) (1.4.1)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from scikit-plot) (3.2.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->scikit-plot) (1.18.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18->scikit-plot) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# misc\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import ast\n",
    "import warnings\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_importance\n",
    "import seaborn as sns\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# ML\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "!pip install scikit-plot\n",
    "import scikitplot as skplt\n",
    "import xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\Jack\\\\Documents_\\\\Thesis_2\\\\Datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"df_final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123637"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Headline', # not a feature for training\n",
    "    'Bias',\n",
    " 'glove_vec300_norm',\n",
    " 'tf_idf',\n",
    " 'negative',\n",
    " 'positive',\n",
    " 'bias_lex_h',\n",
    "'bias_lex_r',\n",
    " 'assertives',\n",
    " 'factives',\n",
    " 'report_verbs',\n",
    " 'implicatives',\n",
    " 'hedges',\n",
    " 'affect (Affect)',\n",
    " 'posemo (Positive Emotions)',\n",
    " 'negemo (Negative Emotions)',\n",
    " 'anx (Anx)',\n",
    " 'anger (Anger)',\n",
    " 'sad (Sad)',\n",
    " 'social (Social)',\n",
    " 'family (Family)',\n",
    " 'friend (Friends)',\n",
    " 'female (Female)',\n",
    " 'male (Male)',\n",
    " 'cogproc (Cognitive Processes)',\n",
    " 'insight (Insight)',\n",
    " 'cause (Causal)',\n",
    " 'discrep (Discrepancies)',\n",
    " 'tentat (Tentative)',\n",
    " 'certain (Certainty)',\n",
    " 'differ (Differentiation)',\n",
    " 'percept (Perceptual Processes)',\n",
    " 'see (See)',\n",
    " 'hear (Hear)',\n",
    " 'feel (Feel)',\n",
    " 'bio (Biological Processes)',\n",
    " 'body (Body)',\n",
    " 'health (Health)',\n",
    " 'sexual (Sexual)',\n",
    " 'ingest (Ingest)',\n",
    " 'drives (Drives)',\n",
    " 'affiliation (Affiliation)',\n",
    " 'achieve (Achievement)',\n",
    " 'power (Power)',\n",
    " 'reward (Reward)',\n",
    " 'risk (Risk)',\n",
    " 'focuspast (Past Focus)',\n",
    " 'focuspresent (Present Focus)',\n",
    " 'focusfuture (Future Focus)',\n",
    " 'relativ (Relativity)',\n",
    " 'motion (Motion)',\n",
    " 'space (Space)',\n",
    " 'time (Time)',\n",
    " 'work (Work)',\n",
    " 'leisure (Leisure)',\n",
    " 'home (Home)',\n",
    " 'money (Money)',\n",
    " 'relig (Religion)',\n",
    " 'death (Death)',\n",
    " 'informal (Informal Language)',\n",
    " 'swear (Swear)',\n",
    " 'netspeak (Netspeak)',\n",
    " 'assent (Assent)',\n",
    " 'nonflu (Nonfluencies)',\n",
    " 'filler (Filler Words)',\n",
    " 'pos_ADJ',\n",
    " 'pos_ADP',\n",
    " 'pos_ADV',\n",
    " 'pos_AUX',\n",
    " 'pos_DET',\n",
    " 'pos_INTJ',\n",
    " 'pos_NOUN',\n",
    " 'pos_PRON',\n",
    " 'pos_PROPN',\n",
    " 'pos_SCONJ',\n",
    " 'pos_VERB',\n",
    " 'pos_X',\n",
    " 'dep_ROOT',\n",
    " 'dep_acl',\n",
    " 'dep_acomp',\n",
    " 'dep_advcl',\n",
    " 'dep_advmod',\n",
    " 'dep_agent',\n",
    " 'dep_amod',\n",
    " 'dep_appos',\n",
    " 'dep_attr',\n",
    " 'dep_aux',\n",
    " 'dep_auxpass',\n",
    " 'dep_cc',\n",
    " 'dep_ccomp',\n",
    " 'dep_compound',\n",
    " 'dep_conj',\n",
    " 'dep_csubj',\n",
    " 'dep_dative',\n",
    " 'dep_dep',\n",
    " 'dep_det',\n",
    " 'dep_dobj',\n",
    " 'dep_expl',\n",
    " 'dep_intj',\n",
    " 'dep_mark',\n",
    " 'dep_neg',\n",
    " 'dep_nmod',\n",
    " 'dep_npadvmod',\n",
    " 'dep_nsubj',\n",
    " 'dep_nsubjpass',\n",
    " 'dep_nummod',\n",
    " 'dep_oprd',\n",
    " 'dep_parataxis',\n",
    " 'dep_pcomp',\n",
    " 'dep_pobj',\n",
    " 'dep_poss',\n",
    " 'dep_preconj',\n",
    " 'dep_predet',\n",
    " 'dep_prep',\n",
    " 'dep_prt',\n",
    " 'dep_punct',\n",
    " 'dep_quantmod',\n",
    " 'dep_relcl',\n",
    " 'dep_xcomp',\n",
    " 'ne_CARDINAL',\n",
    " 'ne_DATE',\n",
    " 'ne_EVENT',\n",
    " 'ne_FAC',\n",
    " 'ne_GPE',\n",
    " 'ne_LANGUAGE',\n",
    " 'ne_LAW',\n",
    " 'ne_LOC',\n",
    " 'ne_MONEY',\n",
    " 'ne_NORP',\n",
    " 'ne_ORDINAL',\n",
    " 'ne_ORG',\n",
    " 'ne_PERCENT',\n",
    " 'ne_PERSON',\n",
    " 'ne_PRODUCT',\n",
    " 'ne_QUANTITY',\n",
    " 'ne_TIME',\n",
    " 'ne_WORK_OF_ART',\n",
    " 'negative_context',\n",
    " 'positive_context',\n",
    " 'bias_lex_h_context',\n",
    "'bias_lex_r_context',\n",
    " 'assertives_context',\n",
    " 'factives_context',\n",
    " 'report_verbs_context',\n",
    " 'implicatives_context',\n",
    " 'hedges_context',\n",
    "'affect (Affect)_context',\n",
    " 'posemo (Positive Emotions)_context',\n",
    " 'negemo (Negative Emotions)_context',\n",
    " 'anx (Anx)_context',\n",
    " 'anger (Anger)_context',\n",
    " 'sad (Sad)_context',\n",
    " 'social (Social)_context',\n",
    " 'family (Family)_context',\n",
    " 'friend (Friends)_context',\n",
    " 'female (Female)_context',\n",
    " 'male (Male)_context',\n",
    " 'cogproc (Cognitive Processes)_context',\n",
    " 'insight (Insight)_context',\n",
    " 'cause (Causal)_context',\n",
    " 'discrep (Discrepancies)_context',\n",
    " 'tentat (Tentative)_context',\n",
    " 'certain (Certainty)_context',\n",
    " 'differ (Differentiation)_context',\n",
    " 'percept (Perceptual Processes)_context',\n",
    " 'see (See)_context',\n",
    " 'hear (Hear)_context',\n",
    " 'feel (Feel)_context',\n",
    " 'bio (Biological Processes)_context',\n",
    " 'body (Body)_context',\n",
    " 'health (Health)_context',\n",
    " 'sexual (Sexual)_context',\n",
    " 'ingest (Ingest)_context',\n",
    " 'drives (Drives)_context',\n",
    " 'affiliation (Affiliation)_context',\n",
    " 'achieve (Achievement)_context',\n",
    " 'power (Power)_context',\n",
    " 'reward (Reward)_context',\n",
    " 'risk (Risk)_context',\n",
    " 'focuspast (Past Focus)_context',\n",
    " 'focuspresent (Present Focus)_context',\n",
    " 'focusfuture (Future Focus)_context',\n",
    " 'relativ (Relativity)_context',\n",
    " 'motion (Motion)_context',\n",
    " 'space (Space)_context',\n",
    " 'time (Time)_context',\n",
    " 'work (Work)_context',\n",
    " 'leisure (Leisure)_context',\n",
    " 'home (Home)_context',\n",
    " 'money (Money)_context',\n",
    " 'relig (Religion)_context',\n",
    " 'death (Death)_context',\n",
    " 'informal (Informal Language)_context',\n",
    " 'swear (Swear)_context',\n",
    " 'netspeak (Netspeak)_context',\n",
    " 'assent (Assent)_context',\n",
    " 'nonflu (Nonfluencies)_context',\n",
    " 'filler (Filler Words)_context',\n",
    " 'pos_ADJ_context',\n",
    " 'pos_ADP_context',\n",
    " 'pos_ADV_context',\n",
    " 'pos_AUX_context',\n",
    " 'pos_DET_context',\n",
    " 'pos_INTJ_context',\n",
    " 'pos_NOUN_context',\n",
    " 'pos_PRON_context',\n",
    " 'pos_PROPN_context',\n",
    " 'pos_SCONJ_context',\n",
    " 'pos_VERB_context',\n",
    " 'pos_X_context',\n",
    " 'dep_ROOT_context',\n",
    " 'dep_acl_context',\n",
    " 'dep_acomp_context',\n",
    " 'dep_advcl_context',\n",
    " 'dep_advmod_context',\n",
    " 'dep_agent_context',\n",
    " 'dep_amod_context',\n",
    " 'dep_appos_context',\n",
    " 'dep_attr_context',\n",
    " 'dep_aux_context',\n",
    " 'dep_auxpass_context',\n",
    " 'dep_cc_context',\n",
    " 'dep_ccomp_context',\n",
    " 'dep_compound_context',\n",
    " 'dep_conj_context',\n",
    " 'dep_csubj_context',\n",
    " 'dep_dative_context',\n",
    " 'dep_dep_context',\n",
    " 'dep_det_context',\n",
    " 'dep_dobj_context',\n",
    " 'dep_expl_context',\n",
    " 'dep_intj_context',\n",
    " 'dep_mark_context',\n",
    " 'dep_neg_context',\n",
    " 'dep_nmod_context',\n",
    " 'dep_npadvmod_context',\n",
    " 'dep_nsubj_context',\n",
    " 'dep_nsubjpass_context',\n",
    " 'dep_nummod_context',\n",
    " 'dep_oprd_context',\n",
    " 'dep_parataxis_context',\n",
    " 'dep_pcomp_context',\n",
    " 'dep_pobj_context',\n",
    " 'dep_poss_context',\n",
    " 'dep_preconj_context',\n",
    " 'dep_predet_context',\n",
    " 'dep_prep_context',\n",
    " 'dep_prt_context',\n",
    " 'dep_punct_context',\n",
    " 'dep_quantmod_context',\n",
    " 'dep_relcl_context',\n",
    " 'dep_xcomp_context',\n",
    " 'ne_CARDINAL_context',\n",
    " 'ne_DATE_context',\n",
    " 'ne_EVENT_context',\n",
    " 'ne_FAC_context',\n",
    " 'ne_GPE_context',\n",
    " 'ne_LAW_context',\n",
    " 'ne_LOC_context',\n",
    " 'ne_MONEY_context',\n",
    " 'ne_NORP_context',\n",
    " 'ne_ORDINAL_context',\n",
    " 'ne_ORG_context',\n",
    " 'ne_PERCENT_context',\n",
    " 'ne_PERSON_context',\n",
    " 'ne_PRODUCT_context',\n",
    " 'ne_QUANTITY_context',\n",
    " 'ne_TIME_context',\n",
    " 'ne_WORK_OF_ART_context',\n",
    " 'ne_LANGUAGE_context']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values:\n",
      "tf_idf 5662\n"
     ]
    }
   ],
   "source": [
    "print('Number of missing values:')\n",
    "mis = (df.isnull().sum()).to_frame()\n",
    "for i, row in mis.iterrows():\n",
    "    if row[0] > 0:\n",
    "        print(i, row[0])\n",
    "\n",
    "# Delete the rows with missing article text:\n",
    "df = df.dropna(subset=['tf_idf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16294"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Headline'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Label\"] = df.Bias.apply(lambda x: 1 if x == \"AllSides Media Bias Rating: Left\" or x == \"AllSides Media Bias Rating: Right\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['Label', 'Bias', 'Headline'], 1)\n",
    "y = df[['Label']]\n",
    "headline = df[['Headline']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Source</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Text</th>\n",
       "      <th>Bias</th>\n",
       "      <th>Subject_Tag</th>\n",
       "      <th>Date</th>\n",
       "      <th>spacy_lg</th>\n",
       "      <th>spacy_lg_dict</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>U.S. News &amp; World Report</td>\n",
       "      <td>COVID Deaths Continue to Decline in U.S.</td>\n",
       "      <td>In a sign that the coronavirus pandemic is beg...</td>\n",
       "      <td>AllSides Media Bias Rating: Lean Left</td>\n",
       "      <td>Coronavirus, Coronavirus Vaccine, Coronavirus ...</td>\n",
       "      <td>May 3rd, 2021</td>\n",
       "      <td>COVID Deaths Continue to Decline in U.S.</td>\n",
       "      <td>[{'text': 'COVID', 'text_low': 'covid', 'pos':...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Wall Street Journal (News)</td>\n",
       "      <td>Vaccines Appear to Be Slowing Spread of Covid-...</td>\n",
       "      <td>Vaccines appear to be starting to curb new Cov...</td>\n",
       "      <td>AllSides Media Bias Rating: Center</td>\n",
       "      <td>Coronavirus, Coronavirus Vaccine, Coronavirus ...</td>\n",
       "      <td>May 3rd, 2021</td>\n",
       "      <td>Vaccines Appear to Be Slowing Spread of Covid-...</td>\n",
       "      <td>[{'text': 'Vaccines', 'text_low': 'vaccines', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Washington Examiner</td>\n",
       "      <td>Pandemic retreat signals vaccines are working</td>\n",
       "      <td>COVID-19 cases and hospitalizations in the Uni...</td>\n",
       "      <td>AllSides Media Bias Rating: Lean Right</td>\n",
       "      <td>Coronavirus, Coronavirus Vaccine, Coronavirus ...</td>\n",
       "      <td>May 3rd, 2021</td>\n",
       "      <td>Pandemic retreat signals vaccines are working</td>\n",
       "      <td>[{'text': 'Pandemic', 'text_low': 'pandemic', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Epoch Times</td>\n",
       "      <td>NYT, Washington Post, NBC Retract Incorrect Re...</td>\n",
       "      <td>The New York Times, The Washington Post, and N...</td>\n",
       "      <td>AllSides Media Bias Rating: Lean Right</td>\n",
       "      <td>Media Industry, Media Bias, New York Times, Wa...</td>\n",
       "      <td>May 2nd, 2021</td>\n",
       "      <td>NYT, Washington Post, NBC Retract Incorrect Re...</td>\n",
       "      <td>[{'text': 'NYT', 'text_low': 'nyt', 'pos': 'PR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The Hill</td>\n",
       "      <td>New York Times, WaPo, NBC retract reports abou...</td>\n",
       "      <td>The New York Times, The Washington Post and NB...</td>\n",
       "      <td>AllSides Media Bias Rating: Center</td>\n",
       "      <td>Media Industry, Media Bias, New York Times, Wa...</td>\n",
       "      <td>May 2nd, 2021</td>\n",
       "      <td>New York Times, WaPo, NBC retract reports abou...</td>\n",
       "      <td>[{'text': 'New', 'text_low': 'new', 'pos': 'PR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      Source  \\\n",
       "0           0    U.S. News & World Report   \n",
       "1           1  Wall Street Journal (News)   \n",
       "2           2         Washington Examiner   \n",
       "3           3             The Epoch Times   \n",
       "4           4                    The Hill   \n",
       "\n",
       "                                            Headline  \\\n",
       "0           COVID Deaths Continue to Decline in U.S.   \n",
       "1  Vaccines Appear to Be Slowing Spread of Covid-...   \n",
       "2      Pandemic retreat signals vaccines are working   \n",
       "3  NYT, Washington Post, NBC Retract Incorrect Re...   \n",
       "4  New York Times, WaPo, NBC retract reports abou...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  In a sign that the coronavirus pandemic is beg...   \n",
       "1  Vaccines appear to be starting to curb new Cov...   \n",
       "2  COVID-19 cases and hospitalizations in the Uni...   \n",
       "3  The New York Times, The Washington Post, and N...   \n",
       "4  The New York Times, The Washington Post and NB...   \n",
       "\n",
       "                                     Bias  \\\n",
       "0   AllSides Media Bias Rating: Lean Left   \n",
       "1      AllSides Media Bias Rating: Center   \n",
       "2  AllSides Media Bias Rating: Lean Right   \n",
       "3  AllSides Media Bias Rating: Lean Right   \n",
       "4      AllSides Media Bias Rating: Center   \n",
       "\n",
       "                                         Subject_Tag           Date  \\\n",
       "0  Coronavirus, Coronavirus Vaccine, Coronavirus ...  May 3rd, 2021   \n",
       "1  Coronavirus, Coronavirus Vaccine, Coronavirus ...  May 3rd, 2021   \n",
       "2  Coronavirus, Coronavirus Vaccine, Coronavirus ...  May 3rd, 2021   \n",
       "3  Media Industry, Media Bias, New York Times, Wa...  May 2nd, 2021   \n",
       "4  Media Industry, Media Bias, New York Times, Wa...  May 2nd, 2021   \n",
       "\n",
       "                                            spacy_lg  \\\n",
       "0           COVID Deaths Continue to Decline in U.S.   \n",
       "1  Vaccines Appear to Be Slowing Spread of Covid-...   \n",
       "2      Pandemic retreat signals vaccines are working   \n",
       "3  NYT, Washington Post, NBC Retract Incorrect Re...   \n",
       "4  New York Times, WaPo, NBC retract reports abou...   \n",
       "\n",
       "                                       spacy_lg_dict  Label  \n",
       "0  [{'text': 'COVID', 'text_low': 'covid', 'pos':...      0  \n",
       "1  [{'text': 'Vaccines', 'text_low': 'vaccines', ...      0  \n",
       "2  [{'text': 'Pandemic', 'text_low': 'pandemic', ...      0  \n",
       "3  [{'text': 'NYT', 'text_low': 'nyt', 'pos': 'PR...      0  \n",
       "4  [{'text': 'New', 'text_low': 'new', 'pos': 'PR...      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines = pd.read_excel(\"Headlines_Tokenized.xlsx\")\n",
    "headlines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values:\n",
      "Source 6\n",
      "Text 5\n",
      "Subject_Tag 285\n"
     ]
    }
   ],
   "source": [
    "print('Number of missing values:')\n",
    "mis = (headlines.isnull().sum()).to_frame()\n",
    "for i, row in mis.iterrows():\n",
    "    if row[0] > 0:\n",
    "        print(i, row[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117975"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16294"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Headline'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_h = headlines[\"spacy_lg_dict\"]\n",
    "y_h = headlines[['Label']]\n",
    "headline_h = headlines[['Headline']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "train_features, test_features, train_labels, test_labels, train_headlines, test_headlines = train_test_split(x, y, headline,\n",
    "                                                                                                             test_size = 0.10, random_state = 42)\n",
    "train_features1, val_features, train_labels1, val_labels, train_headlines1, val_headlines = train_test_split(train_features, train_labels, train_headlines,\n",
    "                                                                                                             test_size = 0.10, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "train_features_h, test_features_h, train_labels_h, test_labels_h, train_headlines_h, test_headlines_h = train_test_split(x_h, y_h, headline_h,\n",
    "                                                                                                             test_size = 0.10, random_state = 42)\n",
    "train_features1_h, val_features_h, train_labels1_h, val_labels_h, train_headlines1_h, val_headlines_h = train_test_split(train_features_h, train_labels_h, train_headlines_h,\n",
    "                                                                                                             test_size = 0.10, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix for XGBoost\n",
    "dtrain = xgboost.DMatrix(train_features, label=train_labels, feature_names=feature_names)\n",
    "dtest = xgboost.DMatrix(test_features, label=test_labels, feature_names=feature_names)\n",
    "dtrain1 = xgboost.DMatrix(train_features1, label=train_labels1, feature_names=feature_names)\n",
    "dval = xgboost.DMatrix(val_features, label=val_labels, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (106177, 268)\n",
      "Training Labels Shape: (106177, 1)\n",
      "Testing Features Shape: (11798, 268)\n",
      "Testing Labels Shape: (11798, 1)\n",
      "Training Features for final model Shape: (95559, 268)\n",
      "Training Labels for final model Shape: (95559, 1)\n",
      "Validation Features Shape: (10618, 268)\n",
      "Validation Labels Shape: (10618, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)\n",
    "print('Training Features for final model Shape:', train_features1.shape)\n",
    "print('Training Labels for final model Shape:', train_labels1.shape)\n",
    "print('Validation Features Shape:', val_features.shape)\n",
    "print('Validation Labels Shape:', val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1_pred = pd.Series(np.random.randint(2, size=len(test_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of b1, test:\n",
      "F1: 0.35\n",
      "Precision: 0.27\n",
      "Recall: 0.51\n",
      "AUC: 0.51\n",
      "Accuracy: 0.5\n",
      "Confusion matrix:\n",
      " [[4347 1511]\n",
      " [4346 1594]]\n"
     ]
    }
   ],
   "source": [
    "print('Performance of b1, test:')\n",
    "print('F1:', round(metrics.f1_score(test_labels,b1_pred),2))\n",
    "print('Precision:', round(metrics.precision_score(test_labels,b1_pred),2))\n",
    "print('Recall:', round(metrics.recall_score(test_labels,b1_pred),2))\n",
    "print('AUC:', round(metrics.roc_auc_score(test_labels,b1_pred),2))\n",
    "print('Accuracy:', round(metrics.accuracy_score(test_labels,b1_pred),2))\n",
    "print('Confusion matrix:\\n', \n",
    "      metrics.confusion_matrix(test_labels,b1_pred).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_pred = test_features.negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of b2, test:\n",
      "F1: 0.13\n",
      "Precision: 0.26\n",
      "Recall: 0.08\n",
      "AUC: 0.5\n",
      "Accuracy: 0.7\n",
      "Confusion matrix:\n",
      " [[7942 2847]\n",
      " [ 751  258]]\n"
     ]
    }
   ],
   "source": [
    "print('Performance of b2, test:')\n",
    "print('F1:', round(metrics.f1_score(test_labels,b2_pred),2))\n",
    "print('Precision:', round(metrics.precision_score(test_labels,b2_pred),2))\n",
    "print('Recall:', round(metrics.recall_score(test_labels,b2_pred),2))\n",
    "print('AUC:', round(metrics.roc_auc_score(test_labels,b2_pred),2))\n",
    "print('Accuracy:', round(metrics.accuracy_score(test_labels,b2_pred),2))\n",
    "print('Confusion matrix:\\n', metrics.confusion_matrix(test_labels,b2_pred).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf_matrix = metrics.confusion_matrix(test_labels,b2_pred)\n",
    "TN = cf_matrix[0][0]\n",
    "FN = cf_matrix[1][0]\n",
    "TP = cf_matrix[1][1]\n",
    "FP = cf_matrix[0][1]\n",
    "fl = [TN, FN, FP, TP]\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "group_names = ['TN','FN','FP','TP']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in fl]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     fl/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap=\"BuPu\")\n",
    "plt.ylabel('Predicted', fontsize=20)\n",
    "plt.xlabel('Actual', fontsize=20)\n",
    "ax.set_ylim([0,2])\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_pred = test_features.apply(lambda row: 1 if row.negative==1 or row.positive==1 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of b3, test:\n",
      "F1: 0.19\n",
      "Precision: 0.25\n",
      "Recall: 0.15\n",
      "AUC: 0.49\n",
      "Accuracy: 0.66\n",
      "Confusion matrix:\n",
      " [[7283 2644]\n",
      " [1410  461]]\n"
     ]
    }
   ],
   "source": [
    "print('Performance of b3, test:')\n",
    "print('F1:', round(metrics.f1_score(test_labels,b3_pred),2))\n",
    "print('Precision:', round(metrics.precision_score(test_labels,b3_pred),2))\n",
    "print('Recall:', round(metrics.recall_score(test_labels,b3_pred),2))\n",
    "print('AUC:', round(metrics.roc_auc_score(test_labels,b3_pred),2))\n",
    "print('Accuracy:', round(metrics.accuracy_score(test_labels,b3_pred),2))\n",
    "print('Confusion matrix:\\n', \n",
    "      metrics.confusion_matrix(test_labels,b3_pred).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "b4_pred = test_features.bias_lex_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of b4, test:\n",
      "F1: 0.08\n",
      "Precision: 0.27\n",
      "Recall: 0.05\n",
      "AUC: 0.5\n",
      "Accuracy: 0.71\n",
      "Confusion matrix:\n",
      " [[8277 2953]\n",
      " [ 416  152]]\n"
     ]
    }
   ],
   "source": [
    "print('Performance of b4, test:')\n",
    "print('F1:', round(metrics.f1_score(test_labels,b4_pred),2))\n",
    "print('Precision:', round(metrics.precision_score(test_labels,b4_pred),2))\n",
    "print('Recall:', round(metrics.recall_score(test_labels,b4_pred),2))\n",
    "print('AUC:', round(metrics.roc_auc_score(test_labels,b4_pred),2))\n",
    "print('Accuracy:', round(metrics.accuracy_score(test_labels,b4_pred),2))\n",
    "print('Confusion matrix:\\n', \n",
    "      metrics.confusion_matrix(test_labels,b4_pred).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5_pred = test_features.bias_lex_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of b5, test:\n",
      "F1: 0.24\n",
      "Precision: 0.24\n",
      "Recall: 0.23\n",
      "AUC: 0.49\n",
      "Accuracy: 0.61\n",
      "Confusion matrix:\n",
      " [[6466 2384]\n",
      " [2227  721]]\n"
     ]
    }
   ],
   "source": [
    "print('Performance of b5, test:')\n",
    "print('F1:', round(metrics.f1_score(test_labels,b5_pred),2))\n",
    "print('Precision:', round(metrics.precision_score(test_labels,b5_pred),2))\n",
    "print('Recall:', round(metrics.recall_score(test_labels,b5_pred),2))\n",
    "print('AUC:', round(metrics.roc_auc_score(test_labels,b5_pred),2))\n",
    "print('Accuracy:', round(metrics.accuracy_score(test_labels,b5_pred),2))\n",
    "print('Confusion matrix:\\n', \n",
    "      metrics.confusion_matrix(test_labels,b5_pred).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biased words: 26.0 %\n",
      "Neutral words: 74.0 %\n"
     ]
    }
   ],
   "source": [
    "print('Biased words:',round(len(y[y['Label']==1])/len(y)*100,0),'%')\n",
    "print('Neutral words:',round(len(y[y['Label']==0])/len(y)*100,0),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\jack\\anaconda3\\lib\\site-packages (4.5.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from transformers) (4.47.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from transformers) (2020.6.8)\n",
      "Requirement already satisfied: requests in c:\\users\\jack\\anaconda3\\lib\\site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\jack\\anaconda3\\lib\\site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\jack\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in c:\\users\\jack\\anaconda3\\lib\\site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: joblib in c:\\users\\jack\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\jack\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in c:\\users\\jack\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\jack\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp38-cp38-win_amd64.whl (1.1 MB)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.96\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "from typing import Dict, List, Optional, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, BertConfig, TFBertForSequenceClassification\n",
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "from transformers import RobertaTokenizer, TFRobertaForSequenceClassification\n",
    "from transformers import ElectraTokenizer, TFElectraForSequenceClassification\n",
    "from transformers import XLNetTokenizer, TFXLNetForSequenceClassification\n",
    "from transformers import LongformerTokenizer, TFLongformerForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed, TF uses python ramdom and numpy library, so these must also be fixed\n",
    "tf.random.set_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "os.environ['PYTHONHASHSEED']=str(0)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'),\n",
       " PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if hardware accelerator available\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\Jack\\\\Documents_\\\\Thesis_2\\\\Datasets\")\n",
    "df_final = pd.read_csv(\"DatasetFull.csv\", encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"Label\"] = df_final.Bias.apply(lambda x: 1 if x == \"AllSides Media Bias Rating: Left\" or x == \"AllSides Media Bias Rating: Right\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified k-Fold instance\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions called in skfold loop\n",
    "\n",
    "def pd_to_tf(df):\n",
    "    \"\"\"convert a pandas dataframe into a tensorflow dataset\"\"\"\n",
    "    target = df.pop('Label')\n",
    "    headline = df.pop('Headline')\n",
    "    return tf.data.Dataset.from_tensor_slices((headline.values, target.values))\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])\n",
    "    plt.show()\n",
    "\n",
    "def tokenize(df):\n",
    "    \"\"\"convert a pandas dataframe into a tensorflow dataset and run hugging face's tokenizer on data\"\"\"\n",
    "    target = df.pop('Label')\n",
    "    headline = df.pop('Headline')\n",
    "\n",
    "    train_encodings = tokenizer(\n",
    "                        headline.tolist(),                      \n",
    "                        add_special_tokens = True, # add [CLS], [SEP]\n",
    "                        truncation = True, # cut off at max length of the text that can go to BERT\n",
    "                        padding = True, # add [PAD] tokens\n",
    "                        return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
    "              )\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dict(train_encodings), \n",
    "         target.tolist()))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_5fold(df_train, model_name, freeze_encoder=True, pretrained=False, plot=False):\n",
    "    \"\"\"\"freeze flags whether encoder layer should be frozen to not destroy transfer learning. Only set to false when enough data is provided\"\"\"\n",
    "\n",
    "    # these variables will be needed for skfold to select indices\n",
    "    Y = df_train['Label']\n",
    "    X = df_train['Headline']\n",
    "\n",
    "    # hyperparams\n",
    "    BUFFER_SIZE = 10000\n",
    "    BATCH_SIZE = 32\n",
    "    k = 1\n",
    "\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    val_prec = []\n",
    "    val_rec = []\n",
    "    val_f1 = []\n",
    "    val_f1_micro = []\n",
    "    val_f1_wmacro = []\n",
    "\n",
    "    for train_index, val_index in skfold.split(X,Y):\n",
    "        print('### Start fold {}'.format(k))\n",
    "\n",
    "        # split into train and validation set\n",
    "        train_dataset = df_train.iloc[train_index]\n",
    "        val_dataset = df_train.iloc[val_index]\n",
    "\n",
    "        # prepare data for transformer\n",
    "        train_dataset = tokenize(train_dataset)\n",
    "        val_dataset = tokenize(val_dataset)\n",
    "\n",
    "        # mini-batch it\n",
    "        train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "        val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        # create new model\n",
    "        if model_name == 'bert':\n",
    "            model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "        if model_name == 'distilbert':\n",
    "            model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "        elif model_name == 'roberta':\n",
    "            model = TFRobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "        elif model_name == 'electra':\n",
    "            model = TFElectraForSequenceClassification.from_pretrained('google/electra-small-discriminator')\n",
    "        elif model_name == 'xlnet':\n",
    "            model = TFXLNetForSequenceClassification.from_pretrained('xlnet-base-cased')\n",
    "\n",
    "\n",
    "        if freeze_encoder == True:\n",
    "            for w in model.get_layer(index=0).weights:\n",
    "                w._trainable = False\n",
    "\n",
    "        # compile it\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5) \n",
    "        model.compile(optimizer=optimizer, loss=model.compute_loss) \n",
    "\n",
    "        # transfer learning\n",
    "        if pretrained == True:\n",
    "            model.get_layer(index=0).set_weights(trained_model_layer) # load bias-specific weights\n",
    "            #model.load_weights('./checkpoints/')\n",
    "\n",
    "        # after 2 epochs without improvement, stop training\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)\n",
    "\n",
    "        # fit it\n",
    "        history = model.fit(train_dataset, epochs=10, validation_data = val_dataset, callbacks=[callback])\n",
    "\n",
    "        # plot history\n",
    "        if plot:\n",
    "            plot_graphs(history,'loss')\n",
    "\n",
    "        # evaluate\n",
    "        loss = model.evaluate(val_dataset)\n",
    "\n",
    "        if model_name == 'xlnet':\n",
    "            yhats = []\n",
    "            for row in df_train.iloc[val_index]['sentence']:\n",
    "                input = tokenizer(row, return_tensors=\"tf\")\n",
    "                output = model(input)\n",
    "                logits = output.logits.numpy()[0]\n",
    "                candidates = logits.tolist()\n",
    "                decision = candidates.index(max(candidates))\n",
    "                yhats.append(decision)\n",
    "        else:\n",
    "            logits = model.predict(val_dataset)  \n",
    "            yhats = []\n",
    "            for i in logits[0]:\n",
    "                # assign class label according to highest logit\n",
    "                candidates = i.tolist()\n",
    "                decision = candidates.index(max(candidates))\n",
    "                yhats.append(decision)\n",
    "\n",
    "        y = []\n",
    "        for text, label in val_dataset.unbatch():   \n",
    "              y.append(label.numpy())\n",
    "\n",
    "        val_loss.append(loss)\n",
    "        val_acc.append(accuracy_score(y, yhats))\n",
    "        val_prec.append(precision_score(y, yhats))\n",
    "        val_rec.append(recall_score(y, yhats))\n",
    "        val_f1.append(f1_score(y, yhats))\n",
    "        val_f1_micro.append(f1_score(y, yhats, average='micro'))\n",
    "        val_f1_wmacro.append(f1_score(y, yhats, average='weighted'))\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        k += 1\n",
    "\n",
    "    return val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Start fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x000002668008C220>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x000002668008C220>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "415/415 [==============================] - ETA: 0s - loss: 0.5738 WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "415/415 [==============================] - 10958s 26s/step - loss: 0.5738 - val_loss: 0.5636\n",
      "Epoch 2/10\n",
      "415/415 [==============================] - 11486s 28s/step - loss: 0.5081 - val_loss: 0.5643\n",
      "104/104 [==============================] - 683s 7s/step - loss: 0.5636\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "### Start fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "415/415 [==============================] - ETA: 0s - loss: 0.5756 WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "415/415 [==============================] - 11098s 27s/step - loss: 0.5756 - val_loss: 0.5687\n",
      "Epoch 2/10\n",
      "415/415 [==============================] - 7842s 19s/step - loss: 0.5284 - val_loss: 0.5733\n",
      "104/104 [==============================] - 800s 8s/step - loss: 0.5687\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "### Start fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "112/415 [=======>......................] - ETA: 1:30:23 - loss: 0.5829"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0e44f6c89ba4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bert-base-uncased'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# without distant signal pretraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_final, model_name='bert', \n\u001b[0m\u001b[0;32m      4\u001b[0m                                                                                             freeze_encoder=False, pretrained=False)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-660cac70a2df>\u001b[0m in \u001b[0;36mrun_model_5fold\u001b[1;34m(df_train, model_name, freeze_encoder, pretrained, plot)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;31m# fit it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;31m# plot history\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \"\"\"\n\u001b[1;32m-> 1661\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# without distant signal pretraining\n",
    "val_loss, val_acc, val_prec, val_rec, val_f1, val_f1_micro, val_f1_wmacro = run_model_5fold(df_final, model_name='bert', \n",
    "                                                                                            freeze_encoder=False, pretrained=False)\n",
    "\n",
    "# inspect metrics\n",
    "loss_cv = np.mean(val_loss)\n",
    "acc_cv = np.mean(val_acc)\n",
    "prec_cv = np.mean(val_prec)\n",
    "rec_cv = np.mean(val_rec)\n",
    "f1_cv = np.mean(val_f1)\n",
    "f1_micro_cv = np.mean(val_f1_micro)\n",
    "f1_wmacro_cv = np.mean(val_f1_wmacro)\n",
    "\n",
    "print('5-Fold CV Loss: {}'.format(loss_cv))\n",
    "print('5-Fold CV Accuracy: {}'.format(acc_cv))\n",
    "print('5-Fold CV Precision: {}'.format(prec_cv))\n",
    "print('5-Fold CV Recall: {}'.format(rec_cv))\n",
    "print('5-Fold CV F1 Score: {}'.format(f1_cv))\n",
    "print('5-Fold CV Micro F1 Score: {}'.format(f1_micro_cv))\n",
    "print('5-Fold CV Weighted Macro F1 Score: {}'.format(f1_wmacro_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
